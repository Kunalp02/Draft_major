{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5PsV-W22-cv",
        "outputId": "f42f37b1-7b86-471e-8060-de43a5bd7c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Set1: [0, 3, 1]\n",
            "Predicted Set2: [1, 2, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Data\n",
        "data = {\n",
        "    'Date': ['11/12/2023', '12/12/2023', '13/12/2023', '14/12/2023', '15/12/2023', '16/12/2023'],\n",
        "    'Set1': [(2, 5, 9), (2, 5, 7), (4, 5, 0), (1, 2, 0), (1, 1, 2), (1, 5, 0)],\n",
        "    'Set2': [(2, 3, 4), (6, 0, 0), (3, 4, 9), (2, 2, 4), (1, 3, 4), (2, 3, 0)]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert the 'Date' column to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
        "\n",
        "# Extract features (days since the first date) from the 'Date' column\n",
        "df['Days'] = (df['Date'] - df['Date'].min()).dt.days\n",
        "\n",
        "# Flatten the tuples in the 'Set1' and 'Set2' columns\n",
        "df['Set1'] = df['Set1'].apply(lambda x: [int(abs(round(num))) % 10 for num in x])\n",
        "df['Set2'] = df['Set2'].apply(lambda x: [int(abs(round(num))) % 10 for num in x])\n",
        "\n",
        "# Separate features (Days) and target variables (Set1 and Set2)\n",
        "X = df[['Days']]\n",
        "y_set1 = df['Set1'].apply(pd.Series).values\n",
        "y_set2 = df['Set2'].apply(pd.Series).values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_set1_train, y_set1_test, y_set2_train, y_set2_test = train_test_split(X, y_set1, y_set2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train linear regression models for Set 1 and Set 2\n",
        "model_set1 = LinearRegression()\n",
        "model_set2 = LinearRegression()\n",
        "\n",
        "model_set1.fit(X_train, y_set1_train)\n",
        "model_set2.fit(X_train, y_set2_train)\n",
        "\n",
        "# Predict the next day's values\n",
        "next_day = datetime.strptime('17/12/2023', '%d/%m/%Y')\n",
        "days_since_first = (next_day - df['Date'].min()).days\n",
        "next_day_features = [[days_since_first]]\n",
        "\n",
        "predicted_set1 = model_set1.predict(next_day_features)\n",
        "predicted_set2 = model_set2.predict(next_day_features)\n",
        "\n",
        "# Convert predictions to a regular Python list and round\n",
        "predicted_set1 = [int(abs(round(num))) % 10 for num in predicted_set1.flatten()]\n",
        "predicted_set2 = [int(abs(round(num))) % 10 for num in predicted_set2.flatten()]\n",
        "\n",
        "print(\"Predicted Set1:\", predicted_set1)\n",
        "print(\"Predicted Set2:\", predicted_set2)\n"
      ]
    }
  ]
}